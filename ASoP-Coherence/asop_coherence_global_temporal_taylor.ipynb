{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/home/nick/python/ASoP_global/ASoP-Coherence')\n",
    "from asop_coherence_global_temporal import get_asop_dict\n",
    "import matplotlib.cm as mpl_cm\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import skill_metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summary_metric(filename,constraint,new_long_name,new_units):\n",
    "    cube = iris.load_cube(filename,constraint)\n",
    "    cube.long_name = new_long_name\n",
    "    cube.units = new_units\n",
    "    return(cube)\n",
    "def load_all_summary_metrics(asop_dict,wet_season_threshold='1d24'):\n",
    "    constraints_longnames_units = [\n",
    "        ('Temporal intermittency on-off metric based on 4 divisions (mean of all months in wet season)','Temporal coherence metric, 4 divs, all wet season, 3hr - '+asop_dict['name'],'1'),\n",
    "        ('Probability of upper division followed by upper division (mean of all months in wet season)','p(on|on), 4 divs, all wet season, 3hr '+asop_dict['name'],'1'),\n",
    "        ('Probability of upper division followed by lower division (mean of all months in wet season)','p(on|off), 4 divs, all wet season, 3hr '+asop_dict['name'],'1'),\n",
    "        ('Probability of lower division followed by upper division (mean of all months in wet season)','p(off|on), 4 divs, all wet season, 3hr '+asop_dict['name'],'1'),\n",
    "        ('Probability of lower division followed by lower division (mean of all months in wet season)','p(off|off), 4 divs, all wet season, 3hr '+asop_dict['name'],'1')\n",
    "    ]\n",
    "    out_cubelist = []\n",
    "    summary_file = asop_dict['desc']+'_asop_temporal_summary_wetseason'+wet_season_threshold+'.nc'\n",
    "    for constraint,long_name,units in constraints_longnames_units:\n",
    "        cube = load_summary_metric(str(asop_dict['dir']/summary_file),constraint,long_name,units)\n",
    "        out_cubelist.append(cube)\n",
    "    return(out_cubelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_autocorr_threshold(cube,lag_length,threshold=0.5,long_name=None,units=None):\n",
    "    import numpy as np\n",
    "    #max_autocorr = cube.collapsed('lag',iris.analysis.MEAN).copy()\n",
    "    lon = cube.coord('longitude')\n",
    "    lat = cube.coord('latitude')\n",
    "    nlon = len(lon.points)\n",
    "    nlat = len(lat.points)\n",
    "    nlag = len(cube.coord('lag').points)\n",
    "#    max_autocorr = iris.cube.Cube(np.ma.empty((nlat,nlon)),dim_coords_and_dims=[(lat,0),(lon,1)])\n",
    "    max_autocorr = np.zeros((nlat,nlon))\n",
    "    for y in range(nlat):\n",
    "        for x in range(nlon):\n",
    "            below_threshold = np.where(cube.data[:,y,x] <= threshold)\n",
    "            if np.sum(below_threshold) >= 1:\n",
    "                max_autocorr[y,x] = np.amin(below_threshold)*lag_length+0.5\n",
    "            else:\n",
    "                max_autocorr[y,x] = nlag*lag_length+0.5\n",
    "    max_autocorr_cube = iris.cube.Cube(data=max_autocorr,dim_coords_and_dims=[(lat,0),(lon,1)],long_name=long_name,units=units,var_name='autocorr_threshold'+str(threshold))\n",
    "    return(max_autocorr_cube) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary_stats(model_cube,obs_cube,region,region_type,region_name,diag_name,model_dict,mask=None):\n",
    "    import pandas as pd\n",
    "    # Average space-time summary metrics over a given region.\n",
    "    # Mask for land-only if requested.\n",
    "    import iris.analysis.stats as istats\n",
    "    grid_constraint = iris.Constraint(latitude=lambda cell: region[0] <= cell <= region[1],\n",
    "                                      longitude=lambda cell: region[2] <= cell <= region[3])\n",
    "    model_region = model_cube.extract(grid_constraint)\n",
    "    obs_region = obs_cube.extract(grid_constraint)\n",
    "    if region_type == 'land' or region_type == 'ocean':\n",
    "        if mask is None:\n",
    "            raise Exception('Computing summary stats over '+region_type+' requires a mask, but mask is None.')\n",
    "        #mask.coord('longitude').guess_bounds()\n",
    "        #mask.coord('latitude').guess_bounds()\n",
    "        mask_regrid = mask.regrid(model_region,iris.analysis.AreaWeighted())\n",
    "        mask_region = mask_regrid.extract(grid_constraint)\n",
    "        print(mask_region)\n",
    "        print(mask_region.data)\n",
    "        if region_type == 'land':\n",
    "            model_region = model_region.copy(data=np.ma.array(model_region.data,mask=np.where(mask_region.data >= 0.5,False,True)))\n",
    "            obs_region = obs_region.copy(data=np.ma.array(obs_region.data,mask=np.where(mask_region.data >= 0.5,False,True)))\n",
    "        if region_type == 'ocean':\n",
    "            model_region = model_region.copy(data=np.ma.array(model_region.data,mask=np.where(mask_region.data < 0.5,False,True)))\n",
    "            obs_region = obs_region.copy(data=np.ma.array(obs_region.data,mask=np.where(mask_region.data < 0.5,False,True)))\n",
    "    weights = iris.analysis.cartography.area_weights(model_region)\n",
    "    model_avg = model_region.collapsed(['longitude','latitude'],iris.analysis.MEAN,weights=weights)\n",
    "    obs_avg = obs_region.collapsed(['longitude','latitude'],iris.analysis.MEAN,weights=weights)\n",
    "    \n",
    "    diff = model_region-obs_region\n",
    "    bias = diff.collapsed(('longitude','latitude'),iris.analysis.MEAN,weights=weights)\n",
    "    rmse = diff.collapsed(('longitude','latitude'),iris.analysis.RMS,weights=weights)\n",
    "    std = model_region.collapsed(('longitude','latitude'),iris.analysis.STD_DEV)\n",
    "    pcorr = istats.pearsonr(model_region,obs_region,weights=weights,common_mask=True) #,corr_coords=('latitude','longitude'))\n",
    "    npcorr = np.corrcoef(model_region.data.flatten(),obs_region.data.flatten())[0,1]\n",
    "    print(npcorr)\n",
    "    #ts = sm.taylor_statistics(model_region.data.flatten(),obs_region.data.flatten(),'data')\n",
    "    ts = [std.data,rmse.data,pcorr.data,bias.data]\n",
    "    print(ts)\n",
    "    return(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpm_dict = get_asop_dict('GPM_IMERG')\n",
    "gpm_temporal_summary,gpm_ponon,gpm_ponoff,gpm_poffon,gpm_poffoff = load_all_summary_metrics(gpm_dict)\n",
    "gpm_autocorr_filename = str(gpm_dict['dir'])+'/'+gpm_dict['desc']+'_asop_temporal_autocorr_wetseason1d24.nc'\n",
    "gpm_autocorr = load_summary_metric(gpm_autocorr_filename,'autocorr_wetseason_precip_mean',None,'Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    ([-20,20,0,360],'trop'),\n",
    "    ([-60,-20,0,360],'sh'),\n",
    "    ([20,60,0,360],'nh'),\n",
    "    ([-60,60,0,360],'glob')\n",
    "]\n",
    "nregions = len(regions)\n",
    "mask_file='/media/nick/lacie_tb3/datasets/land_sea_mask/landfrac_n216e_hadgem3-10.3.nc'\n",
    "mask = iris.load_cube(mask_file,'land_area_fraction')\n",
    "metrics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_threshold=0.5\n",
    "gpm_autocorr_threshold = find_autocorr_threshold(gpm_autocorr,3,threshold=autocorr_threshold,long_name='Temporal autocorr metric, >'+str(autocorr_threshold)+', all wet season, 3hr - GPM',units='Hours')\n",
    "models = ['GPM_IMERG','ACCESS','AWI','BCC','FGOALS','GISS','MIROC','MPI-ESM1','SAM0-UNICON'] # Specify GPM first to get Taylor statistics\n",
    "nmodels = len(models)\n",
    "#model_names=['OBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for region,region_name in regions:\n",
    "    print('--> '+region_name)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    region_types=[\n",
    "        ('both','off','k'),\n",
    "        ('land','on','r'),\n",
    "        ('ocean','on','b')\n",
    "    ]\n",
    "    for region_type,overlay,color in region_types:\n",
    "        print('-->--> '+region_type)\n",
    "        sdev = np.empty(nmodels) \n",
    "        rmsd = np.empty(nmodels)\n",
    "        corr = np.empty(nmodels)\n",
    "        bias = np.empty(nmodels)\n",
    "        for m,model in enumerate(models):\n",
    "            print('-->-->--> '+model)\n",
    "            model_dict = get_asop_dict(model)\n",
    "            model_temporal_summary,model_ponon,model_ponoff,model_poffon,model_poffoff = load_all_summary_metrics(model_dict)\n",
    "            gpm_temporal_summary,gpm_ponon,gpm_ponoff,gpm_poffon,gpm_poffoff = load_all_summary_metrics(gpm_dict)\n",
    "            ts = compute_summary_stats(model_temporal_summary,gpm_temporal_summary,region,region_type,region_name,'temporal_summary',model_dict,mask=mask)\n",
    "            sdev[m] = np.array(ts[0])\n",
    "            rmsd[m] = np.array(ts[1])\n",
    "            corr[m] = np.array(ts[2])\n",
    "            bias[m] = np.array(ts[3])        \n",
    "        sm.taylor_diagram(sdev,rmsd,corr,markerLabel=models,markerLegend='on',markerLabelColor='k',markerColor=color, styleOBS = '-', colOBS = color, markerobs = 'o',markerSize = 8,tickRMSangle = 115, showlabelsRMS = 'on',titleRMS = 'on', titleOBS = 'GPM', checkstats = 'on',overlay=overlay,axismax=0.1,tickrms=[0,0.02,0.04,0.06,0.08,0.1]) \n",
    "        #,cmapzdata=bias,titleColorBar='Bias (hours)',markerDisplayed='colorBar')\n",
    "    plt.savefig('plots/asop_coherence_global_temporal_taylor_3hr_temporalsummary_'+region_name+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region,region_name in regions:\n",
    "    print('--> '+region_name)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    region_types=[\n",
    "        ('both','off','k'),\n",
    "        ('land','on','r'),\n",
    "        ('ocean','on','b')\n",
    "    ]\n",
    "    for region_type,overlay,color in region_types:\n",
    "        print('-->--> '+region_type)\n",
    "        sdev = np.empty(nmodels) \n",
    "        rmsd = np.empty(nmodels)\n",
    "        corr = np.empty(nmodels)\n",
    "        bias = np.empty(nmodels)\n",
    "        for m,model in enumerate(models):\n",
    "            print('-->-->--> '+model)\n",
    "            model_dict = get_asop_dict(model)\n",
    "            model_autocorr_filename = str(model_dict['dir'])+'/'+model_dict['desc']+'_asop_temporal_autocorr_wetseason1d24.nc'\n",
    "            model_autocorr = load_summary_metric(model_autocorr_filename,'autocorr_wetseason_precip_mean',None,'Hours')\n",
    "            model_autocorr_threshold = find_autocorr_threshold(model_autocorr,3,threshold=autocorr_threshold,long_name='Temporal autocorr metric, >'+str(autocorr_threshold)+', all wet season, 3hr - '+model_dict['name'],units='Hours')\n",
    "            ts = compute_summary_stats(model_autocorr_threshold,gpm_autocorr_threshold,region,region_type,region_name,'autocorr_threshold'+str(autocorr_threshold),model_dict,mask=mask)\n",
    "            sdev[m] = np.array(ts[0])\n",
    "            rmsd[m] = np.array(ts[1])\n",
    "            corr[m] = np.array(ts[2])\n",
    "            bias[m] = np.array(ts[3])        \n",
    "        sm.taylor_diagram(sdev,rmsd,corr,markerLabel=models,markerLegend='on',markerLabelColor='k',markerColor=color, styleOBS = '-', colOBS = color, markerobs = 'o',markerSize = 8,tickRMSangle = 115, showlabelsRMS = 'on',titleRMS = 'on', titleOBS = 'GPM', checkstats = 'on',overlay=overlay,axismax=25,tickrms=[0,5,10,15,20,25]) \n",
    "        #,cmapzdata=bias,titleColorBar='Bias (hours)',markerDisplayed='colorBar')\n",
    "    plt.savefig('plots/asop_coherence_global_temporal_taylor_3hr_autocorr'+str(autocorr_threshold)+'_'+region_name+'.png',dpi=200)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}