{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda49259213bd59438180089695f6a95129",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nick/python/asop_global/ASoP-Coherence')\n",
    "import asop_coherence as asop\n",
    "import iris\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "import iris.coord_categorisation\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "from iris.util import unify_time_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cmip6(asop_dict):\n",
    "    from iris.util import unify_time_units\n",
    "    from iris.experimental.equalise_cubes import equalise_attributes\n",
    "    from iris.time import PartialDateTime\n",
    "\n",
    "    cubelist = iris.load(str(asop_dict['dir'])+'/pr_3hr*.nc3') # Use NetCDF3 data to save compute time\n",
    "    unify_time_units(cubelist)\n",
    "    equalise_attributes(cubelist)\n",
    "    cube = cubelist.concatenate_cube()\n",
    "    cube.coord('time').bounds = None\n",
    "    constraint = iris.Constraint(time = lambda cell: PartialDateTime(year=asop_dict['start_year']) <= cell <= PartialDateTime(year=asop_dict['stop_year']),longitude = lambda cell: 60 <= cell <= 90, latitude = lambda cell: 10 <= cell <= 40)\n",
    "    cube = cube.extract(constraint)\n",
    "    return(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asop_dict(key):\n",
    "    datapath=Path('/media/nick/lacie_tb31/data_from_gill/CMIP6')\n",
    "    if key == 'AWI':\n",
    "        asop_dict={\n",
    "            'dir': datapath/'AWI-CM-1-1-MR',\n",
    "            'name': 'AWI',\n",
    "            'start_year': 1990,\n",
    "            'stop_year': 2014,\n",
    "            'dt': 10800,\n",
    "            'legend_name': 'AWI',\n",
    "            'region': [-90,90,0,360],\n",
    "            'color': 'red',\n",
    "            'symbol': '<'\n",
    "        }\n",
    "    elif key == 'BCC':\n",
    "        asop_dict={\n",
    "            'dir': datapath/'BCC-CSM2-MR',\n",
    "            'name': 'BCC',\n",
    "            'dt': 10800,\n",
    "            'legend_name': 'BCC',\n",
    "            'region': [-90,90,0,360],\n",
    "            'color': 'blue',\n",
    "            'symbol': '8'\n",
    "        }\n",
    "    else:\n",
    "        raise Exception('No dictionary for '+key)\n",
    "    return(asop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [ ([-30,30,0,360],'land','trop_land'),\n",
    "            ([-30,30,0,360],'ocean','trop_ocean'),\n",
    "            ([-90,-30,0,360],'land','sh_land'),\n",
    "            ([-90,-30,0,360],'ocean','sh_ocean'),\n",
    "            ([30,90,0,360],'land','nh_land'),\n",
    "            ([30,90,0,360],'ocean','nh_ocean'),\n",
    "            ([-90,90,0,360],'land','glob_land'),\n",
    "            ([-90,90,0,360],'ocean','glob_ocean')]\n",
    "datasets=['AWI'] #,'BCC']\n",
    "n_datasets=len(datasets)\n",
    "n_regions = len(regions)\n",
    "space_metrics_plot = np.empty((n_datasets,n_regions))\n",
    "time_metrics_plot = np.empty((n_datasets,n_regions))\n",
    "all_datasets = []\n",
    "all_colors = []\n",
    "all_symbols = []\n",
    "all_regions = []\n",
    "for box,mask_type,region_name in regions:\n",
    "\tall_regions.append(region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clim_contribution(precip):\n",
    "    import iris.coord_categorisation\n",
    "    iris.coord_categorisation.add_month_number(precip,'time')\n",
    "    month_clim = precip.aggregated_by('month_number',iris.analysis.SUM)\n",
    "    ann_clim = month_clim.collapsed('time',iris.analysis.SUM)\n",
    "    month_frac = month_clim/ann_clim\n",
    "    month_frac.var_name='clim_precip_frac'\n",
    "    month_frac.long_name='Fractional monthly precipitation contribution to annual precipitation'\n",
    "    return(month_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model in datasets:\n",
    "model = 'AWI'\n",
    "asop_dict = get_asop_dict(model)\n",
    "precip = load_cmip6(asop_dict)\n",
    "#precip.convert_units('mm day-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_contrib_filename='pr_clim_month_frac.'+str(asop_dict['start_year'])+'-'+str(asop_dict['stop_year'])+'.nc'\n",
    "clim_contrib_file=asop_dict['dir']/clim_contrib_filename\n",
    "if clim_contrib_file.exists():\n",
    "    clim_contrib = iris.load_cube(str(clim_contrib_file))\n",
    "else:\n",
    "    clim_contrib = compute_clim_contribution(precip)\n",
    "    iris.save(clim_contrib,str(clim_contrib_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wet_season(precip,clim_contrib,threshold=1.0/24.0):\n",
    "    month_list = []\n",
    "    for m,month in enumerate(clim_contrib.coord('month_number').points):\n",
    "        if clim_contrib.data[m] > threshold:\n",
    "            month_list.append(month)\n",
    "    month_constraint = iris.Constraint(month_number=month_list) #PartialDateTime(month=month_list))\n",
    "    wet_season_cube = precip.extract(month_constraint)\n",
    "    return(wet_season_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_temporal_summary(precip,clim_contrib,ndivs,twod=False,min_precip_threshold=1/86400.0,wet_season_threshold=1.0/24.0):\n",
    "    # Compute temporal summary metric only\n",
    "    iris.coord_categorisation.add_month_number(precip,'time')\n",
    "    lon_coord = precip.coord('longitude')\n",
    "    lat_coord = precip.coord('latitude')\n",
    "    nlon = len(lon_coord.points)\n",
    "    nlat = len(lat_coord.points)\n",
    "    lower_thresh = iris.cube.Cube(data=np.empty((nlat,nlon)),dim_coords_and_dims=[(lat_coord,0),(lon_coord,1)])\n",
    "    lower_thresh.var_name='lower_threshold'\n",
    "    lower_thresh.long_name='Lower (off) threshold based on '+str(ndivs)+' divisions'\n",
    "    upper_thresh = lower_thresh.copy()\n",
    "    upper_thresh.var_name='upper_threshold'\n",
    "    upper_thresh.long_name='Upper (on) threshold based on '+str(ndivs)+' divisions'\n",
    "    if twod:\n",
    "        time_inter = lower_thresh.copy()\n",
    "        time_inter.var_name='temporal_onoff_metric'\n",
    "        time_inter.long_name='Temporal intermittency on-off metric based on '+str(ndivs)+' divisions'\n",
    "        onon_freq = lower_thresh.copy()\n",
    "        onon_freq.var_name='freq_onon'\n",
    "        onoff_freq = lower_thresh.copy()\n",
    "        onoff_freq.var_name='freq_onoff'\n",
    "        offon_freq = lower_thresh.copy()\n",
    "        offon_freq.var_name='freq_offon'\n",
    "        offoff_freq = lower_thresh.copy()\n",
    "        offoff_freq.var_name='freq_offoff'\n",
    "\n",
    "    # Use cube slices to avoid loading all data into memory\n",
    "    for t,t_slice in enumerate(precip.slices(['time'])):\n",
    "        lat = t // nlon\n",
    "        lon = t % nlon\n",
    "        month_list = []\n",
    "        print(lat,lon)\n",
    "        for m,month in enumerate(clim_contrib.coord('month_number').points):\n",
    "            if clim_contrib.data[m,lat,lon] > wet_season_threshold:\n",
    "                month_list.append(month)\n",
    "        if len(month_list) > 1:\n",
    "            month_constraint = iris.Constraint(month_number=month_list)\n",
    "            wet_season = t_slice.extract(month_constraint)\n",
    "            #wet_season = find_wet_season(t_slice,clim_contrib[:,lat,lon])\n",
    "            this_precip = wet_season.data[np.where(wet_season.data > min_precip_threshold)] \n",
    "            nt = np.size(this_precip)\n",
    "            if nt > ndivs:\n",
    "                this_lower,this_upper,this_offoff,this_offon,this_onoff,this_onon = compute_onoff_metric(wet_season.data,this_precip.data)\n",
    "                lower_thresh.data[lat,lon] = this_lower\n",
    "                upper_thresh.data[lat,lon] = this_upper\n",
    "                offoff_freq.data[lat,lon] = this_offoff\n",
    "                offon_freq.data[lat,lon] = this_offon\n",
    "                onoff_freq.data[lat,lon] = this_onoff\n",
    "                onon_freq.data[lat,lon] = this_onon\n",
    "            else:\n",
    "                lower_thresh.data[lat,lon] = np.nan\n",
    "                upper_thresh.data[lat,lon] = np.nan\n",
    "                offoff_freq.data[lat,lon] = np.nan\n",
    "                offon_freq.data[lat,lon] = np.nan\n",
    "                onoff_freq.data[lat,lon] = np.nan\n",
    "                onon_freq.data[lat,lon] = np.nan\n",
    "        else:\n",
    "            lower_thresh.data[lat,lon] = np.nan\n",
    "            upper_thresh.data[lat,lon] = np.nan\n",
    "            offoff_freq.data[lat,lon] = np.nan\n",
    "            offon_freq.data[lat,lon] = np.nan\n",
    "            onoff_freq.data[lat,lon] = np.nan\n",
    "            onon_freq.data[lat,lon] = np.nan\n",
    "\n",
    "    time_inter = 0.5*((onon_freq+offoff_freq)-(onoff_freq+offon_freq))\n",
    "    out_cubelist = [time_inter,onon_freq,onoff_freq,offon_freq,offoff_freq,lower_thresh,upper_thresh]\n",
    "    return(out_cubelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True,parallel=True)\n",
    "def compute_onoff_metric(wet_season,this_precip):\n",
    "    lower_thresh = np.percentile(this_precip,25)\n",
    "    upper_thresh = np.percentile(this_precip,75)\n",
    "    upper_mask = np.where(wet_season >= upper_thresh,1,0)\n",
    "    lower_mask = np.where(wet_season <= lower_thresh,1,0)\n",
    "    non = np.sum(upper_mask)\n",
    "    noff = np.sum(lower_mask)\n",
    "    onon = upper_mask + np.roll(upper_mask,1)\n",
    "    onon_count = np.count_nonzero(np.where(onon == 2,1,0))\n",
    "    onoff = upper_mask + np.roll(lower_mask,1)\n",
    "    onoff_count = np.count_nonzero(np.where(onoff == 2,1,0))\n",
    "    offon = lower_mask + np.roll(upper_mask,1)\n",
    "    offon_count = np.count_nonzero(np.where(offon == 2,1,0))\n",
    "    offoff = lower_mask + np.roll(lower_mask,1)\n",
    "    offoff_count = np.count_nonzero(np.where(offoff == 2,1,0))\n",
    "    onon_freq = onon_count/float(non)\n",
    "    onoff_freq = onoff_count/float(non)\n",
    "    offon_freq = offon_count/float(noff)\n",
    "    offoff_freq = offoff_count/float(noff)\n",
    "\n",
    "    return(lower_thresh,upper_thresh,offoff_freq,offon_freq,onoff_freq,onon_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precipitation_flux / (kg m-2 s-1)   (time: 73048; latitude: 33; longitude: 33)\n     Dimension coordinates:\n          time                           x                -              -\n          latitude                       -                x              -\n          longitude                      -                -              x\n     Attributes:\n          Conventions: CF-1.7 CMIP-6.2\n          NCO: 4.7.2\n          activity_id: CMIP\n          branch_method: standard\n          branch_time_in_child: 0.0\n          branch_time_in_parent: 54421.0\n          cmor_version: 3.4.0\n          comment: includes both liquid and solid phases\n          data_specs_version: 01.00.27\n          experiment: all-forcing simulation of the recent past\n          experiment_id: historical\n          external_variables: areacella\n          forcing_index: 1\n          frequency: 3hr\n          further_info_url: https://furtherinfo.es-doc.org/CMIP6.AWI.AWI-CM-1-1-MR.historical.none...\n          grid: All grid attributes are set for the native grid and based on information...\n          grid_label: gn\n          initialization_index: 1\n          institution: Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research,...\n          institution_id: AWI\n          license: CMIP6 model data produced by Alfred Wegener Institute is licensed under...\n          mip_era: CMIP6\n          nominal_resolution: 100 km\n          original_name: pr\n          parent_activity_id: CMIP\n          parent_experiment_id: piControl\n          parent_mip_era: CMIP6\n          parent_source_id: AWI-CM-1-1-MR\n          parent_time_units: days since 2401-01-01 00:00:00\n          parent_variant_label: r1i1p1f1\n          physics_index: 1\n          product: model-output\n          realization_index: 1\n          realm: atmos\n          source: AWI-CM 1.1 MR (2018): \naerosol: none\natmos: ECHAM6.3.04p1 (T127L95 native...\n          source_id: AWI-CM-1-1-MR\n          source_type: AOGCM\n          sub_experiment: none\n          sub_experiment_id: none\n          table_id: 3hr\n          table_info: Creation Date:(30 July 2018) MD5:fa9bc503f57fb067bf398cab2c4ba77e\n          title: AWI-CM-1-1-MR output prepared for CMIP6\n          variable_id: pr\n          variant_label: r1i1p1f1\n     Cell methods:\n          mean: area, time\nFractional monthly precipitation contribution to annual precipitation / (1) (time: 12; latitude: 33; longitude: 33)\n     Dimension coordinates:\n          time                                                                   x             -              -\n          latitude                                                               -             x              -\n          longitude                                                              -             -              x\n     Auxiliary coordinates:\n          month_number                                                           x             -              -\n     Attributes:\n          Conventions: CF-1.7\n0 0\n0 1\n0 2\n0 3\n0 4\n0 5\n0 6\n0 7\n0 8\n0 9\n0 10\n0 11\n0 12\n0 13\n0 14\n0 15\n0 16\n0 17\n0 18\n0 19\n0 20\n0 21\n0 22\n0 23\n0 24\n0 25\n0 26\n0 27\n0 28\n0 29\n0 30\n0 31\n0 32\n1 0\n1 1\n1 2\n1 3\n1 4\n1 5\n1 6\n1 7\n1 8\n1 9\n1 10\n1 11\n1 12\n1 13\n1 14\n1 15\n1 16\n1 17\n1 18\n1 19\n1 20\n1 21\n1 22\n1 23\n1 24\n1 25\n1 26\n1 27\n1 28\n1 29\n1 30\n1 31\n1 32\n2 0\n2 1\n2 2\n2 3\n2 4\n2 5\n2 6\n"
    }
   ],
   "source": [
    "print(precip)\n",
    "print(clim_contrib)\n",
    "time_inter = compute_temporal_summary(precip,clim_contrib,4,twod=True)\n",
    "iris.save(time_inter,'asop_coherence_global_cmip6_timeinter.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}